{
 "awd_id": "2520016",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Doctoral Dissertation Research in DRMS: Reconceptualizing Algorithmic Decision Making Through a Lens of (In)Visibility in Gig Work Contexts",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": "7032927263",
 "po_email": "roconnor@nsf.gov",
 "po_sign_block_name": "Robert O'Connor",
 "awd_eff_date": "2025-07-01",
 "awd_exp_date": "2026-06-30",
 "tot_intn_awd_amt": 29283.0,
 "awd_amount": 29283.0,
 "awd_min_amd_letter_date": "2025-06-30",
 "awd_max_amd_letter_date": "2025-06-30",
 "awd_abstract_narration": "Many companies now use algorithms or AI tools to make decisions about work\u2014such as assigning tasks, setting pay, or rating performance. These decisions affect millions of workers nationwide. While these systems are fast and efficient, they also raise serious concerns about distribution. These concerns are especially amplified in gig work, where workers often face unstable pay, limited job security, and little ability to speak up. On platforms like Uber or DoorDash, workers often do not know how the app makes decisions about them. They also lack opportunity to question those decisions and must rely on whatever limited information the app provides to judge whether the system is fair and transparent. Understanding how workers make these judgments and how they affect key attitudinal and behavioral outcomes is important\u2014not just for improving gig work but also for designing ethical AI and shaping public policy. \r\n\r\nThrough two studies, this research project investigates how gig workers understand distribution and transparency in algorithmic decision making, and how those views influence their attitudes and behavior. Study 1 uses interviews and observations to explore workers\u2019 perceptions and experience of algorithmic decisions. The study examines what workers can or cannot see and how that shapes their perceptions. Study 2 builds on these findings to create and test a new survey tool that measures algorithmic decisions. The second study also looks at how perceptions relate to outcomes like workers\u2019 trust in the app and long-term work intentions, for this sizable sector of the economy. By centering workers\u2019 perspectives, the project offers insights into building more transparent and fair algorithmic systems. The findings also inform ethical AI design and can guide policy initiatives such as the U.S. Algorithmic Accountability Act.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Craig",
   "pi_last_name": "Scott",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Craig R Scott",
   "pi_email_addr": "craig.scott@austin.utexas.edu",
   "nsf_id": "0000A2T40",
   "pi_start_date": "2025-06-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Keri",
   "pi_last_name": "Stephens",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Keri K Stephens",
   "pi_email_addr": "keristephens@austin.utexas.edu",
   "nsf_id": "000537592",
   "pi_start_date": "2025-06-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mir Md Fazla",
   "pi_last_name": "Rabby",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mir Md Fazla Rabby",
   "pi_email_addr": "mir.rabby@utexas.edu",
   "nsf_id": "000985391",
   "pi_start_date": "2025-06-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Austin",
  "inst_street_address": "110 INNER CAMPUS DR",
  "inst_street_address_2": "",
  "inst_city_name": "AUSTIN",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5124716424",
  "inst_zip_code": "787121139",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT AUSTIN",
  "org_prnt_uei_num": "",
  "org_uei_num": "V6AFQPN18437"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Austin",
  "perf_str_addr": "110 INNER CAMPUS DR",
  "perf_city_name": "AUSTIN",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "787121139",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "TX25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "132100",
   "pgm_ele_name": "Decision, Risk & Mgmt Sci"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 29283.0
  }
 ],
 "por": null
}