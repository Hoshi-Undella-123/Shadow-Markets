{
 "awd_id": "2451108",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: Towards Real-World Robotic Manipulation: Learning Abstract State and Action Representations from Visual and Execution Data",
 "cfda_num": "47.041, 47.070",
 "org_code": "05010000",
 "po_phone": "7032922095",
 "po_email": "kwimmer@nsf.gov",
 "po_sign_block_name": "Karl Wimmer",
 "awd_eff_date": "2025-08-15",
 "awd_exp_date": "2027-07-31",
 "tot_intn_awd_amt": 174998.0,
 "awd_amount": 174998.0,
 "awd_min_amd_letter_date": "2025-06-03",
 "awd_max_amd_letter_date": "2025-06-03",
 "awd_abstract_narration": "Robotic systems have already found widespread adoption in controlled environments such as manufacturing and logistics, where tasks follow well-defined rules. However, they struggle in unstructured, dynamic, real-world settings that demand adaptability and autonomy -- challenges that humans handle with ease. Humans excel at abstract reasoning,  allowing them to perform complex tasks without constant attention to low-level details. This research project aims to equip robots with similar capabilities, enabling them to learn abstract representations of their environment and actions through experience. By enhancing the ability of robotic agents to plan and execute tasks in real world settings, this research could drive advancements in automation, assistive care, and disaster response. Additionally, the project intends to contribute to STEM education through outreach programs for high school students and research opportunities for undergraduate students. The findings will be disseminated through leading robotics conferences and peer-reviewed journals, ensuring broad visibility within the research community. Moreover, the results will inform and enhance robotics courses and all software and datasets produced will be openly shared, fostering collaboration and further advancements in the field.\r\n\r\nThis project aims to advance robotic manipulation in unstructured environments by enabling robots to autonomously learn abstract representations of states and actions from sensory and execution data. Existing planning methods have been successful in controlled settings by using task planners to reason abstractly about complex tasks, providing reliability, explainability, and transparency. However, they rely on human-specified representations, which are impractical in real-world scenarios with unknown objects and noisy sensor data. In contrast, purely data-driven approaches can learn directly from raw sensor data, reducing the need for manual specification but struggling with generalization and lacking interpretability, limiting their deployment in dynamic environments. Research funded by this award seeks to address these issues by developing a framework that learns abstract state and action representations from experience and seamlessly incorporating them into existing manipulation planners. Research activities will focus on designing methods for autonomous real-world data collection, designing algorithms to extract structured representations, and adapting decision-making strategies to leverage learned abstractions. Experimental validation will be conducted on real-world robotic platforms to assess the effectiveness of the learned abstractions. If successful, this research will enhance robotic adaptability, transparency, and efficiency that could significantly expand applicability of autonomous manipulation in open-world environments such as household tasks, assistive care, and construction. Robots capable of abstract reasoning will be better equipped to handle long-horizon tasks like rearrangement, packaging, and sorting. The results will be disseminated through leading robotics conferences and peer-reviewed journals, with software and datasets openly shared to support further research and educational initiatives.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Constantinos",
   "pi_last_name": "Chamzas",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Constantinos C Chamzas",
   "pi_email_addr": "cchamzas@wpi.edu",
   "nsf_id": "0000A060Z",
   "pi_start_date": "2025-06-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Worcester Polytechnic Institute",
  "inst_street_address": "100 INSTITUTE RD",
  "inst_street_address_2": "",
  "inst_city_name": "WORCESTER",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "5088315000",
  "inst_zip_code": "016092280",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "MA02",
  "org_lgl_bus_name": "WORCESTER POLYTECHNIC INSTITUTE",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJNQME41NBU4"
 },
 "perf_inst": {
  "perf_inst_name": "Worcester Polytechnic Institute",
  "perf_str_addr": "100 INSTITUTE RD",
  "perf_city_name": "WORCESTER",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "016092247",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "MA02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "144Y00",
   "pgm_ele_name": "FRR-Foundationl Rsrch Robotics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "6840",
   "pgm_ref_txt": "ROBOTICS"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 174998.0
  }
 ],
 "por": null
}