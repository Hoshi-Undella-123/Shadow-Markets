{
 "awd_id": "2442295",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Addressing Hallucinations for Trustworthy Large-scale Multi-Modality Learning",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032922706",
 "po_email": "ccaragea@nsf.gov",
 "po_sign_block_name": "Cornelia Caragea",
 "awd_eff_date": "2025-07-01",
 "awd_exp_date": "2030-06-30",
 "tot_intn_awd_amt": 499728.0,
 "awd_amount": 305002.0,
 "awd_min_amd_letter_date": "2025-06-17",
 "awd_max_amd_letter_date": "2025-06-17",
 "awd_abstract_narration": "The rapid rise of large-scale multimodal models (LMMs) has promoted their advancement in numerous fields, including social media analysis and healthcare. However, while LMMs have shown outstanding performance, they can produce misleading outputs because these models do not know what they do not know, raising concerns about their reliability. The inaccurate, irrelevant, or unintelligible output produced by LMMs is often called hallucinations. Addressing the hallucination problem in LMMs is an important topic in the next five years since it will improve their trustworthiness and impact in many other fields. This project will develop novel hallucination mitigation approaches to improve the trustworthiness and applications of LMMs in healthcare, including sample use cases of tobacco advertisement prevention and autism behavior prediction. Outcomes from the research will impact the field by providing a foundational and practical study needed for future research. It will also train students to conduct and use research to improve community health and mental health outcomes.\r\n\r\nThere are three primary factors leading to hallucinations in LMMs. First, it is widely understood that biased data distribution causes significant challenges in data-driven responsible AI approaches. However, biased distribution influence on predictions is also a leading cause of hallucinations in LMMs. Second, the misalignment between input modalities could result in the LMMs overconfidently relying on a particular input modality and ignoring others. As a result, the LMMs could hallucinate the predictions based on the dominant modality. Third, training LMMs often requires large-scale training data. The limited data could result in hallucinations in LMMs due to the lack of knowledge and diverse information. The overarching goal of this project is to develop robust and trustable LMMs to mitigate hallucination in large language models. First, to address the imbalanced data, new learning approaches will be introduced to mitigate the hallucinations caused by imbalanced data. Second, novel shuffling learning approaches will be developed to address the problem of misalignment across input modalities. Third, to overcome the problem of limited data, new adaptive learning approaches will be developed to improve the performance and trustworthiness of the LMMs. The LMMs in this project are then deployed into practical healthcare applications. The research effort in this project will pave the way to develop new theoretical and practical approaches to distribution modeling, contrastive learning, and shuffling learning to address hallucinations in LMMs.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Khoa",
   "pi_last_name": "Luu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Khoa Luu",
   "pi_email_addr": "khoaluu@uark.edu",
   "nsf_id": "000784241",
   "pi_start_date": "2025-06-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Arkansas",
  "inst_street_address": "1125 W MAPLE ST STE 316",
  "inst_street_address_2": "",
  "inst_city_name": "FAYETTEVILLE",
  "inst_state_code": "AR",
  "inst_state_name": "Arkansas",
  "inst_phone_num": "4795753845",
  "inst_zip_code": "727013124",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "AR03",
  "org_lgl_bus_name": "UNIVERSITY OF ARKANSAS",
  "org_prnt_uei_num": "",
  "org_uei_num": "MECEHTM8DB17"
 },
 "perf_inst": {
  "perf_inst_name": "University of Arkansas",
  "perf_str_addr": "1125 W MAPLE ST STE 316",
  "perf_city_name": "FAYETTEVILLE",
  "perf_st_code": "AR",
  "perf_st_name": "Arkansas",
  "perf_zip_code": "727013124",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "AR03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002829DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 305002.0
  }
 ],
 "por": null
}