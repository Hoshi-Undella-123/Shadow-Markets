{
 "awd_id": "2530002",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: RI:Small: Use-Inspired RL for Many-Agent Contexts: Co-opetition, Partial Observability, and Dynamic Types",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032920000",
 "po_email": "eplaku@nsf.gov",
 "po_sign_block_name": "Erion Plaku",
 "awd_eff_date": "2026-01-01",
 "awd_exp_date": "2028-12-31",
 "tot_intn_awd_amt": 299664.0,
 "awd_amount": 299664.0,
 "awd_min_amd_letter_date": "2025-08-04",
 "awd_max_amd_letter_date": "2025-08-04",
 "awd_abstract_narration": "Artificial intelligence (AI) is evolving from answering our questions to acting on our behalf. However, we live in a complex world where individuals and groups must both cooperate and compete to achieve their goals, often without clear insight into others' behavior or intentions. For example, in business, teams work toward shared objectives while balancing their own priorities and competing for resources, frequently uncertain about how others will act. Similarly, AI agents acting on our behalf must navigate this uncertainty, learning when to collaborate and when to pursue their own goals. As another example, defender agents on a cybernetwork collaborate with other defenders while being adversarial against attackers. These scenarios raise important questions about how AI agents can learn to both cooperate and compete with one another, and how large multi-agent systems can be guided toward desirable outcomes. This project explores these challenges by studying how agents learn from experience, anticipate others' actions, and determine the amount of data needed to learn effectively. The project steps out of disciplinary boundaries to bring concepts from statistical mechanics, control theory, and management sciences to bear upon these challenges. The project will also educate students in the theory and practice of AI that is relevant to learning and will produce program libraries for public use.\r\n \r\nThis project studies reinforcement learning (RL) for an agent sharing its environment with a large collection of other learning agents whose features may change. The approach seeks concurrency and Bayesian optimality of many-agent RL via full decentralization, and spans three research thrusts. The first thrust investigates techniques from statistical mechanics to let an RL agent effectively model a collective of other learning agents organized in various topologies, and studies the emergent behavior in the system. The second thrust investigates computational representations for mixed-motive settings and the stability of decentralized learning in such settings, specifically exploiting Lyapunov techniques from control theory. The third thrust investigates RL under agent type dynamism due to unknown events. The research results will be validated using existing benchmarks and in two use-inspired domains: one that models a business organization and another one that simulates a cybersecurity environment. The broader impact of this project is creating a foundation for the science of autonomous decentralized learning in systems with many agents with an emphasis on data efficiency. This will inform the management science related to future businesses and agentic organizations, as well as the science of successful human-AI teaming.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Prashant",
   "pi_last_name": "Doshi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Prashant Doshi",
   "pi_email_addr": "pdoshi@uga.edu",
   "nsf_id": "000219732",
   "pi_start_date": "2025-08-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Georgia Research Foundation Inc",
  "inst_street_address": "310 E CAMPUS RD RM 409",
  "inst_street_address_2": "",
  "inst_city_name": "ATHENS",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "7065425939",
  "inst_zip_code": "306021589",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "GA10",
  "org_lgl_bus_name": "UNIVERSITY OF GEORGIA RESEARCH FOUNDATION, INC.",
  "org_prnt_uei_num": "",
  "org_uei_num": "NMJHD63STRC5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Georgia Research Foundation Inc",
  "perf_str_addr": "310 E CAMPUS RD RM 409",
  "perf_city_name": "ATHENS",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "306021589",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "GA10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 299664.0
  }
 ],
 "por": null
}