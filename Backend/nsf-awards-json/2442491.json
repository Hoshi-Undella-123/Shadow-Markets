{
 "awd_id": "2442491",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Foundational 4D Human Video Understanding",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2025-06-15",
 "awd_exp_date": "2030-05-31",
 "tot_intn_awd_amt": 599955.0,
 "awd_amount": 341618.0,
 "awd_min_amd_letter_date": "2025-06-06",
 "awd_max_amd_letter_date": "2025-06-06",
 "awd_abstract_narration": "Understanding human behavior from video is a challenging and transformative area of research, with applications in robotics, assistive technologies, neuroscience, and beyond. Humans do not act in isolation; their actions are shaped by their surroundings, interactions with others, and the objects they use. This project aims to develop a new foundational paradigm for understanding humans in 4D \u2014 their 3D state over time \u2014 from any type of video. Unlike current methods, this approach integrates people with their physical and social context, enabling a deeper understanding of human activities. By creating a computational framework that can analyze both exo-centric (third-person) and ego-centric (first-person) videos, the project addresses the limitations of existing methods and supports downstream applications such as assistive technologies, wearable AI, and data analysis for neuroscience and practical everyday tasks. The resulting advancements will enable robots to learn from observing humans, assistive technologies to better support users, and wearable devices to provide richer context for human activity, contributing to safer, more effective, and accessible technologies with far-reaching impacts across science, industry, and society.\r\n\r\nThis project will design a scalable, transformer-based model to capture the 4D state of humans and their situational context, including surrounding environments, social interactions, and object use. By leveraging recent advancements in 3D pose estimation, scene reconstruction, and large-scale multimodal models, the research will unify these aspects into a single flexible framework. The approach accommodates various types of video inputs, whether single or multiple views, and will include comprehensive evaluations of its performance. The resulting open-source code, models, and data will provide tools for researchers to advance 4D human understanding and related fields. This project also integrates research with education by developing curricula that combine vision, geometry, and machine learning, and by creating summer research opportunities for a wide range of students, along with accessible online tools to engage a broader audience.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Angjoo",
   "pi_last_name": "Kanazawa",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Angjoo Kanazawa",
   "pi_email_addr": "kanazawa@berkeley.edu",
   "nsf_id": "000822329",
   "pi_start_date": "2025-06-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "1608 4TH ST STE 201",
  "perf_city_name": "BERKELEY",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947101749",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002829DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 341618.0
  }
 ],
 "por": null
}