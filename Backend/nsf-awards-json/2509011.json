{
 "awd_id": "2509011",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Theoretical Foundations of Efficient and Scalable Graph Learning",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032922948",
 "po_email": "slevine@nsf.gov",
 "po_sign_block_name": "Stacey Levine",
 "awd_eff_date": "2025-07-01",
 "awd_exp_date": "2028-06-30",
 "tot_intn_awd_amt": 187000.0,
 "awd_amount": 187000.0,
 "awd_min_amd_letter_date": "2025-06-18",
 "awd_max_amd_letter_date": "2025-06-18",
 "awd_abstract_narration": "This project aims to develop mathematical foundations for understanding and improving graph neural networks (GNNs), which are widely used machine learning models for data with graph structures. Such data arises in recommender systems, molecular modeling and a range of scientific and technological domains. While GNNs have achieved notable empirical success, key theoretical challenges remain, including limited expressivity, suboptimal performance on specific graph types, and performance degradation in deep architectures. This project addresses these challenges by building and analyzing principled models that are both expressive and computationally efficient. The research outcomes will contribute to the development of robust machine learning tools for analyzing complex graph-structured data. Undergraduate and high school students will be actively involved through mentoring and educational programs.\r\n\r\nThe project combines mathematical analysis and model design to advance the theory and practice of graph learning. It will pursue three interconnected directions: (1) developing GNN architectures for solving quadratic programs, a broad class of optimization problems; (2) analyzing the expressivity of subgraph GNNs on graphs with bounded cycles, which frequently occur in applications; and (3) designing new approaches to mitigate the oversmoothing phenomenon in deep GNNs. The work will draw on techniques from graph theory, optimization, and neural network theory. These efforts aim to provide a deeper theoretical understanding and practical advancements in graph learning.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ziang",
   "pi_last_name": "Chen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ziang Chen",
   "pi_email_addr": "ziang@mit.edu",
   "nsf_id": "000984302",
   "pi_start_date": "2025-06-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 MASSACHUSETTS AVE",
  "perf_city_name": "CAMBRIDGE",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126600",
   "pgm_ele_name": "APPLIED MATHEMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  },
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 187000.0
  }
 ],
 "por": null
}