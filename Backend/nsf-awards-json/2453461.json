{
 "awd_id": "2453461",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: III: Small: Perception-Augmented Databases for Efficient and Robust Visual Analytics",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032922232",
 "po_email": "sdraghic@nsf.gov",
 "po_sign_block_name": "Sorin Draghici",
 "awd_eff_date": "2025-07-15",
 "awd_exp_date": "2028-06-30",
 "tot_intn_awd_amt": 399999.0,
 "awd_amount": 399999.0,
 "awd_min_amd_letter_date": "2025-07-10",
 "awd_max_amd_letter_date": "2025-07-10",
 "awd_abstract_narration": "Data visualization is a powerful tool commonly used by practitioners to understand, analyze, and identify interesting patterns in their data. However, due to limitations in human perception and issues of efficiency in data processing and rendering, it has become standard practice for data analysts to work with only a sampled subset of their data. However, deriving samples that preserve key aspects of the underlying data is not straightforward. Analysts looking at a sample should be able to draw the same conclusions as they would from the complete original data. Unfortunately, this is often not the case. For example, while uniform random sampling is the most accessible method to data analysts in practice, it frequently fails to represent outliers and patterns, leading to missed critical insights and distorted perceptions of the underlying data trends. This is not a rare occurrence, as interesting insights often lie within outlier behaviors, edge cases, or uncommon aspects of the data. This is detrimental to visual data analysis: sampling choices can critically impact the accuracy and efficiency of common visual analytics tasks, and, when chosen poorly, can lead analysts to incorrect conclusions. This project addresses the gap at the core of this issue: data systems do not model human perception, and sampling algorithms do not optimize for it. Explicitly accounting for human perception in samples can create more effective visualizations and reduce the risk of distorting patterns and trends in the data. Considering that the data analytics market generated revenue of almost US$23 Billion in 2019 and is projected to reach US$132 Billion by 2026, improvements in the visual analytics domain are positioned to have a tremendous impact on the economy. As decisions often rely on visual analysis, improved accuracy in inferences will lead to better decision-making and data communication, which can also support data-driven decision-making by policy-makers and improve the interpretability and credibility of data analyses for the general public.\r\n\r\n\r\n\r\nThis project will augment data management systems with explicit models of perceptual features of the data, and will contribute algorithms that use perceptual models in data selection for visualization tasks. The investigators will explore the suitability of established saliency models, commonly used in computer vision, that predict areas of a visualization that attract viewers' attention as a proxy of perception. The project will make the following intellectual contributions: (1) A prototype perception-augmented database, with novel representations for perceptual saliency data and optimized storage strategies to minimize overhead. (2) Novel sampling algorithms that use perceptual models toward their data selection objectives, including optimizations for on-the-fly sample augmentation and robustness across a range of visualization tasks. (3) Perception-aware compressed representations of data that can be used towards approximate visualizations for increased efficiency and real-time performance. (4) Novel measures for perceptual quality in samples. These advances will enable data scientists to draw accurate insights from visual analysis, within an efficient and robust analytics pipeline.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Alexandra",
   "pi_last_name": "Meliou",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Alexandra Meliou",
   "pi_email_addr": "ameli@cs.umass.edu",
   "nsf_id": "000637003",
   "pi_start_date": "2025-07-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Massachusetts Amherst",
  "inst_street_address": "101 COMMONWEALTH AVE",
  "inst_street_address_2": "",
  "inst_city_name": "AMHERST",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "4135450698",
  "inst_zip_code": "010039252",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "MA02",
  "org_lgl_bus_name": "UNIVERSITY OF MASSACHUSETTS",
  "org_prnt_uei_num": "VGJHK59NMPK9",
  "org_uei_num": "VGJHK59NMPK9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Massachusetts Amherst",
  "perf_str_addr": "101 COMMONWEALTH AVE",
  "perf_city_name": "AMHERST",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "010039252",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "MA02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 399999.0
  }
 ],
 "por": null
}