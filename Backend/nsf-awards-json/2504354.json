{
 "awd_id": "2504354",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: SHF: Medium: Semantic Aware Code Generation with LLMs",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032920000",
 "po_email": "amarcus@nsf.gov",
 "po_sign_block_name": "Andrian Marcus",
 "awd_eff_date": "2025-10-01",
 "awd_exp_date": "2028-09-30",
 "tot_intn_awd_amt": 225000.0,
 "awd_amount": 225000.0,
 "awd_min_amd_letter_date": "2025-06-30",
 "awd_max_amd_letter_date": "2025-06-30",
 "awd_abstract_narration": "Large Language Models (LLMs) show great promise for generating source code and automating programming tasks. But these models are error-prone and can produce code with subtle bugs. This poses a risk for deploying LLMs in industrial settings for software engineering tasks - the subtly erroneous code generated by LLMs can expose vulnerabilities that compromise system security. It has been shown that the weakness of LLMs for code generation primarily stems from not accounting for the semantic properties of programs when training, using, and evaluating these models. This project aims to improve LLMs\u2019 ability to generate high-quality code by deeply integrating program analyses with all the stages in the life cycle of LLMs: training, code generation, and evaluation. \r\n\r\nThis project develops novel quantitative program analyses techniques to provide feedback to LLMs during training and decoding. First, the project leverages symbolic execution and Bayesian program analyses to design meaningful metrics to evaluate LLM-generated code. This project then uses program scores to train a differentiable reward model that can assess the quality of partial or complete generated code. At training time, inspired by Reinforcement Learning with Human Feedback (RLHF), this project uses the reward model for fine-tuning LLMs to generate high-quality code. To improve code generation at decoding time, this project leverages the reward model and similarity-based program ranking techniques to constrain and prune the decoding tree. Finally, this project develops semantics-guided metrics and collects new benchmarks consisting of realistic coding tasks for training and evaluating code LLMs.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ravi",
   "pi_last_name": "Mangal",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ravi Mangal",
   "pi_email_addr": "ravi.mangal@colostate.edu",
   "nsf_id": "000948678",
   "pi_start_date": "2025-06-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Colorado State University",
  "inst_street_address": "601 S HOWES ST",
  "inst_street_address_2": "",
  "inst_city_name": "FORT COLLINS",
  "inst_state_code": "CO",
  "inst_state_name": "Colorado",
  "inst_phone_num": "9704916355",
  "inst_zip_code": "805212807",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "CO02",
  "org_lgl_bus_name": "COLORADO STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "LT9CXX8L19G1"
 },
 "perf_inst": {
  "perf_inst_name": "Colorado State University",
  "perf_str_addr": "601 S HOWES ST",
  "perf_city_name": "FORT COLLINS",
  "perf_st_code": "CO",
  "perf_st_name": "Colorado",
  "perf_zip_code": "805212807",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "CO02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7944",
   "pgm_ref_txt": "SOFTWARE ENG & FORMAL METHODS"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 225000.0
  }
 ],
 "por": null
}